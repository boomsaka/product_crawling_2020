{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(file_name):\n",
    "    with open(file_name+\".csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        csv_f = csv.writer(f)\n",
    "        csv_f.writerow(columns)\n",
    "\n",
    "def save_data(data, file_name):\n",
    "    with open(file_name+\".csv\", \"a\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        csv_f = csv.writer(f)\n",
    "        csv_f.writerow([data.get(key) for key in columns])\n",
    "\n",
    "def extract_data(resp, file_name, skip_first=False):\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "    \n",
    "    #------------------------------\n",
    "    base = base = soup.find_all(\"div\", class_=\"inner\")[1:-1]\n",
    "    #------------------------------\n",
    "    \n",
    "    for n, each in enumerate(base):\n",
    "        extract_detail(each, file_name)\n",
    "    \n",
    "    #------------------------------\n",
    "    #print(re.findall(r\"\\d+\\.?\\d*\", soup.find(\"span\", class_=\"page current\").text)[0])\n",
    "    #------------------------------\n",
    "    \n",
    "    #------------------------------\n",
    "    pages = max_pages\n",
    "    #------------------------------\n",
    "    \n",
    "    return pages\n",
    "\n",
    "def extract_all_data(ori_url, sup):\n",
    "    resp = requests.get(ori_url, headers=headers, verify=False)\n",
    "    if resp.ok:\n",
    "        total_pages = extract_data(resp, sup, skip_first=True)\n",
    "    else:\n",
    "        print('''The connection to the website failed, please check the url or anti-crawler.''')\n",
    "    \n",
    "    #------------------------------\n",
    "    for p in range(2, int(total_pages)+1):\n",
    "        time.sleep(3)\n",
    "\n",
    "        #------------------------------\n",
    "        url = ori_url+\"?page={}\".format(p)\n",
    "        #------------------------------\n",
    "\n",
    "        resp = requests.get(url, headers=headers, verify=False)\n",
    "        if resp.ok:\n",
    "            try:\n",
    "                extract_data(resp, sup)\n",
    "            except:\n",
    "                break\n",
    "    #------------------------------\n",
    "            \n",
    "def extract_detail(each, file_name=False):\n",
    "    \n",
    "    #------------------------------\n",
    "    brand = \"lakepajamas\"\n",
    "    product = each.find(\"span\", class_=\"title uppercase futura\").text.strip(\"\\n\")\n",
    "    prices = \"$\"+re.findall(r\"\\d+\\.?\\d*\", each.find(\"span\", class_=\"price floatright\").text)[0]\n",
    "    ori_price = now_price = prices\n",
    "    img_link = \"https:\"+each.find(\"img\").get(\"src\")\n",
    "    product_link = \"https://lakepajamas.com\" + each.find(\"a\").get(\"href\")\n",
    "    #------------------------------\n",
    "    \n",
    "    if file_name:\n",
    "        save_data(dict(zip(columns, [brand, product, ori_price, now_price, img_link, product_link])), file_name)   \n",
    "\n",
    "def download_img(img_url, file_name):\n",
    "    resq = requests.get(img_url)\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(resq.content)\n",
    "        \n",
    "def get_img(ori_file, sup):\n",
    "    df = pd.read_csv(ori_file,encoding=\"utf-8\")\n",
    "    os.mkdir(sup+\"_images\")\n",
    "    for n, url in df[\"image url\"].iteritems():\n",
    "        download_img(url,\"./{}/\".format(sup+\"_images\")+url.split(\"/\")[-1].split(\"?\")[0])\n",
    "        if n%5==0: time.sleep(1)\n",
    "            \n",
    "def compress_file(zipfilename, dirname):\n",
    "    if os.path.isfile(dirname):\n",
    "        with zipfile.ZipFile(zipfilename, 'w') as z:\n",
    "            z.write(dirname)\n",
    "    else:\n",
    "        with zipfile.ZipFile(zipfilename, 'w') as z:\n",
    "            for root, dirs, files in os.walk(dirname):\n",
    "                for single_file in files:\n",
    "                    if single_file != zipfilename:\n",
    "                        filepath = os.path.join(root, single_file)\n",
    "                        z.write(filepath)\n",
    "\n",
    "def mkdir(base_url):\n",
    "    tar_path = base_url.split(\".com\")[0].strip(\"https://\")\n",
    "    if \"www\" in tar_path:\n",
    "        tar_path = tar_path.split(\".\")[-1]\n",
    "    isExists=os.path.exists(tar_path)\n",
    "    if not isExists:\n",
    "        os.mkdir(tar_path)\n",
    "        print(\"parent folder created\")\n",
    "    return os.chdir(tar_path)\n",
    "\n",
    "def folder_exc(folder_name):\n",
    "    compress_file(folder_name+\".zip\", folder_name)\n",
    "    shutil.rmtree(folder_name)\n",
    "    return os.chdir(os.path.pardir)\n",
    "\n",
    "def main(base_url, sup, maxi_pages):\n",
    "    mkdir(base_url)\n",
    "    url = base_url.format(sup)\n",
    "    global columns, headers, max_pages\n",
    "    max_pages = maxi_pages\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleW'\n",
    "                      'ebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "    }\n",
    "    columns = [\"brand\",\"product\",\"original price\",\"current price\",\"image url\",\"product url\"]\n",
    "    create_csv(sup)\n",
    "    extract_all_data(url, sup)\n",
    "    get_img(sup+\".csv\", sup)\n",
    "    folder_exc(sup+\"_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent folder created\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in [\"men\"]:\n",
    "        main(\"https://lakepajamas.com/collections/{}\", i, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------the following is for purpose of testing-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleW'\n",
    "                      'ebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"https://lakepajamas.com/collections/sleep\", headers=headers, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\d+\\.?\\d*\", soup.find(\"span\", class_=\"page current\").text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = soup.find_all(\"div\", class_=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dd5b416dddd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meach\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m91\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "each = base[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"inner centertext\">\n",
       "<div class=\"table\">\n",
       "<div class=\"cell\">\n",
       "<div class=\"title\">Let's be friends.</div>\n",
       "<div class=\"text\">\n",
       "                Sign up for our newsletter and receive 10%  <br/>\n",
       "                off your next order. You'll be the first to<br/>\n",
       "                know about new collections and special offers.\n",
       "              </div>\n",
       "<div class=\"form clearfix\">\n",
       "<!--<form action=\"//lakeweekendwear.us9.list-manage.com/subscribe/post?u=ac1214824a787d2c222326e7d&amp;id=6b6bebdac5\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n",
       "                    <input type=\"text\" name=\"EMAIL\" class=\"futura floatleft\" value=\"Your email address\" onblur=\"if(this.value == '') { this.value='Your email address'}\" onfocus=\"if (this.value == 'Your email address') {this.value=''}\" />\n",
       "                    <div style=\"position: absolute; left: -5000px;\"><input type=\"text\" name=\"b_ac1214824a787d2c222326e7d_6b6bebdac5\" tabindex=\"-1\" value=\"\"></div>\n",
       "                    <input type=\"hidden\" value=\"Yes\" name=\"MMERGE5\" class=\"\" id=\"mce-MMERGE5\">\n",
       "                    <input type=\"submit\" value=\"Subscribe\" class=\"floatright\" onclick=\"ga('send', 'event', 'email', 'click', 'submit');\"/>\n",
       "                </form>-->\n",
       "<!-- KLAVIYO -->\n",
       "<form action=\"//manage.kmail-lists.com/subscriptions/subscribe\" autocomplete=\"off\" data-ajax-submit=\"//manage.kmail-lists.com/ajax/subscriptions/subscribe\" id=\"popup_signup\" method=\"GET\" novalidate=\"novalidate\" target=\"_blank\">\n",
       "<input name=\"g\" type=\"hidden\" value=\"HgyyTX\"/>\n",
       "<div class=\"clearfix\">\n",
       "<input autocapitalize=\"off\" autocorrect=\"off\" class=\"futura floatleft\" name=\"email\" onblur=\"if(this.value == '') { this.value='Your email address'}\" onfocus=\"if (this.value == 'Your email address') {this.value=''}\" type=\"text\" value=\"Your email address\"/>\n",
       "<input class=\"floatright\" onclick=\"ga('send', 'event', 'email', 'click', 'submit');\" type=\"submit\" value=\"Subscribe\"/>\n",
       "</div>\n",
       "<div class=\"klaviyo_messages futura\" style=\"font-size:12px; letter-spacing:0; line-height:1.4; text-align:center;\">\n",
       "<div class=\"success_message\" style=\"display:none; margin-bottom:5px;\"></div>\n",
       "<div class=\"error_message\" style=\"display:none; margin-bottom:5px; color:#ff0000;\"></div>\n",
       "</div>\n",
       "</form>\n",
       "<script src=\"//www.klaviyo.com/media/js/public/klaviyo_subscribe.js\" type=\"text/javascript\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "                  KlaviyoSubscribe.attachToForms('#popup_signup', {\n",
       "                    extra_properties: {\n",
       "                      $source: 'Website Popup Form'\n",
       "                    }\n",
       "                  });\n",
       "                </script>\n",
       "<!-- END KLAVIYO -->\n",
       "</div>\n",
       "<div class=\"later futura\"><a href=\"#\">Maybe later, I'm ready to shop!</a></div>\n",
       "</div>\n",
       "</div>\n",
       "<a class=\"close\" href=\"#\"></a>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Long Pyjama Set'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#brand = each.find(\"span\", class_=\"faux-link\").text\n",
    "#brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pima Shorts Set in Hydrangea'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each.find(\"span\", class_=\"title uppercase futura\").text.strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$84'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"$\"+re.findall(r\"\\d+\\.?\\d*\", each.find(\"span\", class_=\"price floatright\").text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://lakepajamas.com/collections/sleep/products/hydrangea-shorts-set'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://lakepajamas.com\" + each.find(\"a\").get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cdn.shopify.com/s/files/1/0505/6125/products/shorts_hydrangea.jpg?v=1590771055'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https:\"+each.find(\"img\").get(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = \"lakepajamas\"\n",
    "product = each.find(\"span\", class_=\"title uppercase futura\").text.strip(\"\\n\")\n",
    "prices = \"$\"+re.findall(r\"\\d+\\.?\\d*\", each.find(\"span\", class_=\"price floatright\").text)[0]\n",
    "ori_price = now_price = prices\n",
    "img_link = \"https:\"+each.find(\"img\").get(\"src\")\n",
    "product_link = \"https://lakepajamas.com\" + each.find(\"a\").get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_soup = BeautifulSoup(requests.get(product_link, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.princessetamtam.com/dw/image/v2/ABBK_PRD/on/demandware.static/-/Sites-ptt-master/default/dw0727d5b2/MDODO293_1950_PF1.jpg?sw=700&sh=865&sm=cut'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_soup.find(\"a\", class_=\"slick-image\").find(\"img\").get(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number: 2003\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for folder in [i for i in os.listdir() if os.path.isdir(i)]:\n",
    "    for f in os.listdir(folder):\n",
    "        if \"csv\" in f:\n",
    "            n += pd.read_csv(folder+\"/\"+f).shape[0]\n",
    "print(\"Total number:\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
