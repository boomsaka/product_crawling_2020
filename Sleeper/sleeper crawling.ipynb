{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 86.0.4240.22 mac64] driver in cache \n",
      "File found in cache by path [/Users/mandili/.wdm/drivers/chromedriver/86.0.4240.22/mac64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "\n",
    "URL = 'https://the-sleeper.com/en/type-men/pajamas-en/'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get(URL)\n",
    "\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "products = []\n",
    "for i in soup.find_all('div',{'class':'gi-title'}):\n",
    "    products.append((str(i.text).strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "product_links = []\n",
    "for i in soup.find_all('a',{'class':'vd-grid-text'}):\n",
    "    product_links.append(i.get('href'))\n",
    "print(len(product_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prices = []\n",
    "for i in soup.find_all('div',{'class':'gi-price'}):\n",
    "    if i.find('del') != None:\n",
    "        original_prices.append(str(i.find('del').find('span').text).replace('\\xa0$',''))\n",
    "    else:\n",
    "        original_prices.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prices = []\n",
    "for i in soup.find_all('div',{'class':'gi-price'}):\n",
    "    if(i.find('ins')) == None:\n",
    "        current_prices.append(str(i.find('span').text).strip().replace('\\xa0$',''))\n",
    "    else:\n",
    "        current_prices.append(str(i.find('ins').span.text).replace('\\xa0$',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = []\n",
    "for i in soup.find_all('div',{'class':'gi-img'}):\n",
    "    pics.append(i.img.get('data-src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests as req\n",
    "\n",
    "os.mkdir('photos')\n",
    "i = 1\n",
    "for index, link in enumerate(pics):\n",
    "    img_data = req.get(link).content\n",
    "    with open('photos/'+str(index+1)+'.png','wb+') as f:\n",
    "        f.write(img_data)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_names = [\"product\", \"original price\", 'current price', 'product link', 'picture link']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "df['product'] = products\n",
    "df['original price'] = original_prices\n",
    "df['current price'] = current_prices\n",
    "df['product link'] = product_links\n",
    "df['picture link'] = pics\n",
    "df.to_csv('sleep-men-pj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cream Linen Unisex Pajama Set with Pants',\n",
       " 'Azure Linen Unisex Pajama Set with Pants',\n",
       " 'Coal Black Unisex Pajama Set with Pants',\n",
       " 'Unisex Sepia Linen Pajama Set with Pants',\n",
       " 'Navy Unisex Pajama Set with Pants',\n",
       " 'Cream Linen Unisex Pajama Set with Shorts',\n",
       " 'Azure Linen Unisex Pajama Set with Shorts',\n",
       " 'Unisex Coal Black Linen Pajama Set with Shorts',\n",
       " 'Unisex Navy Linen Pajama Set with Shorts',\n",
       " 'Unisex Sepia Linen Pajama Set with Shorts',\n",
       " 'Frank Underwood Pajama Set with Pants']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
